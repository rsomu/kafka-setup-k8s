---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  labels: 
    app: kafka
spec:
  clusterIP: None
  ports:
  - name: kafka-port
    port: 9092
  # [podname].broker.kafka.svc.kpxcluster.local
  - name: mtx-port
    port: 7071
  selector:
    app: kafka
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: kafka-jmx-prom-config
data:
  kafka-2_0_0.yml: |
    lowercaseOutputName: true
    lowercaseOutputLabelNames: false
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: broker-config
data:
  init.sh: |-
    #!/bin/bash
    set -x

    KAFKA_BROKER_ID=${HOSTNAME##*-}
    sed -i "s/#init#broker.id=#init#/broker.id=$KAFKA_BROKER_ID/" /etc/kafka/server.properties

  server.properties: |-
    delete.topic.enable=true
    num.network.threads=3
    num.io.threads=8
    log.flush.interval.ms=1000
    log.flush.interval.messages=100000
    num.recovery.threads.per.data.dir=1
    offsets.topic.replication.factor=1
    transaction.state.log.replication.factor=1
    transaction.state.log.min.isr=1
    #socket.send.buffer.bytes=102400
    default.replication.factor=2
    #socket.receive.buffer.bytes=102400
    #socket.request.max.bytes=104857600
    log.dirs=/var/lib/kafka/data
    num.partitions=16
    log.retention.hours=168
    log.segment.bytes=1073741824
    # 1GB
    #log.retention.check.interval.ms=300000
    zookeeper.connect=czk:2181
    zookeeper.connection.timeout.ms=6000
    group.initial.rebalance.delay.ms=0

  log4j.properties: |-
    log4j.rootLogger=INFO, stdout

    log4j.appender.stdout=org.apache.log4j.ConsoleAppender
    log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
    log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n

    log4j.appender.kafkaAppender=org.apache.log4j.DailyRollingFileAppender
    log4j.appender.kafkaAppender.DatePattern='.'yyyy-MM-dd-HH
    log4j.appender.kafkaAppender.File=${kafka.logs.dir}/server.log
    log4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout
    log4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

    log4j.appender.stateChangeAppender=org.apache.log4j.DailyRollingFileAppender
    log4j.appender.stateChangeAppender.DatePattern='.'yyyy-MM-dd-HH
    log4j.appender.stateChangeAppender.File=${kafka.logs.dir}/state-change.log
    log4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout
    log4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

    log4j.appender.requestAppender=org.apache.log4j.DailyRollingFileAppender
    log4j.appender.requestAppender.DatePattern='.'yyyy-MM-dd-HH
    log4j.appender.requestAppender.File=${kafka.logs.dir}/kafka-request.log
    log4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout
    log4j.appender.requestAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

    log4j.appender.cleanerAppender=org.apache.log4j.DailyRollingFileAppender
    log4j.appender.cleanerAppender.DatePattern='.'yyyy-MM-dd-HH
    log4j.appender.cleanerAppender.File=${kafka.logs.dir}/log-cleaner.log
    log4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout
    log4j.appender.cleanerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

    log4j.appender.controllerAppender=org.apache.log4j.DailyRollingFileAppender
    log4j.appender.controllerAppender.DatePattern='.'yyyy-MM-dd-HH
    log4j.appender.controllerAppender.File=${kafka.logs.dir}/controller.log
    log4j.appender.controllerAppender.layout=org.apache.log4j.PatternLayout
    log4j.appender.controllerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

    log4j.appender.authorizerAppender=org.apache.log4j.DailyRollingFileAppender
    log4j.appender.authorizerAppender.DatePattern='.'yyyy-MM-dd-HH
    log4j.appender.authorizerAppender.File=${kafka.logs.dir}/kafka-authorizer.log
    log4j.appender.authorizerAppender.layout=org.apache.log4j.PatternLayout
    log4j.appender.authorizerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

    # Change the two lines below to adjust ZK client logging
    log4j.logger.org.I0Itec.zkclient.ZkClient=INFO
    log4j.logger.org.apache.zookeeper=INFO

    # Change the two lines below to adjust the general broker logging level (output to server.log and stdout)
    log4j.logger.kafka=INFO
    log4j.logger.org.apache.kafka=INFO

    # Change to DEBUG or TRACE to enable request logging
    log4j.logger.kafka.request.logger=WARN, requestAppender
    log4j.additivity.kafka.request.logger=false

    log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender
    log4j.additivity.kafka.network.RequestChannel$=false

    log4j.logger.kafka.controller=TRACE, controllerAppender
    log4j.additivity.kafka.controller=false

    log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender
    log4j.additivity.kafka.log.LogCleaner=false

    log4j.logger.state.change.logger=TRACE, stateChangeAppender
    log4j.additivity.state.change.logger=false

    log4j.logger.kafka.authorizer.logger=WARN, authorizerAppender
    log4j.additivity.kafka.authorizer.logger=false
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
spec:
  selector:
    matchLabels:
      app: kafka
  serviceName: kafka
  replicas: 4
  template:
    metadata:
      labels:
        app: kafka
      annotations:
    spec:
      schedulerName: stork
      terminationGracePeriodSeconds: 30
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: px/running
                operator: NotIn
                values:
                - "false"
              - key: px/storage
                operator: NotIn
                values:
                - "false"
              - key: px/enabled
                operator: NotIn
                values:
                - "false"
      containers:
      - name: broker
        image: solsson/kafka:2.4.1@sha256:533983c99eb7f44e4a4c75bd2f6c2d79d005420e1344f7c579d53ae79381e602
        env:
        - name: KAFKA_LOG4J_OPTS
          value: -Dlog4j.configuration=file:/etc/kafka/log4j.properties
        - name: JMX_PORT
          value: "8091"
        - name: KAFKA_OPTS
          value: "-javaagent:/opt/kafka/prometheus/jmx_prometheus_javaagent-0.13.0.jar=7071:/opt/kafka/prometheus/kafka-2_0_0.yml"
        - name: KAFKA_HEAP_OPTS
          value: "-Xmx8G -Xms4G"
        ports:
        - containerPort: 9092
          name: kafka-port
        - containerPort: 7071
          name: mtx-port
        command:
        - ./bin/kafka-server-start.sh
        - /etc/kafka/server.properties
        resources:
          requests:
            memory: 64Gi
            cpu: 24
          limits:
            memory: 64Gi
            cpu: 34
        readinessProbe:
          tcpSocket:
            port: 9092
          timeoutSeconds: 1
        volumeMounts:
        - name: config
          mountPath: /etc/kafka
        - name: data
          mountPath: /var/lib/kafka/data
        - name: kafka-jmx-prom-config-vol
          mountPath: /opt/kafka/prometheus/kafka-2_0_0.yml
          subPath: kafka-2_0_0.yml
        - name: jmx-prometheus-javaagent-jar-vol
          mountPath: /opt/kafka/prometheus/jmx_prometheus_javaagent-0.13.0.jar
          subPath: jmx_prometheus_javaagent-0.13.0.jar
      volumes:
      - name: config
        configMap:
          name: broker-config
      - name: kafka-jmx-prom-config-vol
        configMap:
          name: kafka-jmx-prom-config
      - name: jmx-prometheus-javaagent-jar-vol
        configMap:
          name: jmx-prometheus-javaagent-jar
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      storageClassName: px-sc-kafka-repl2
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 400Gi
---
